{"cells":[{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.datasets import fetch_lfw_people\n","from sklearn.datasets import fetch_olivetti_faces\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","from sklearn.decomposition import PCA\n","from sklearn.svm import SVC\n","import matplotlib.pyplot as plt\n","import cv2\n","import random\n","from skimage.color import rgb2gray\n","import pickle\n","import os\n","dirname = os.path.abspath('')\n","datasets_path = os.path.join(dirname, 'Datasets')\n","people_path = os.path.join(datasets_path, 'Our faces')\n","parameters_path = os.path.join(dirname, 'PCA Parameters\\Our faces')"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["def load_our_dataset():\n","    #  Loop over every directory in people path\n","    y = dict()\n","    images = []\n","    i=0\n","    min_width = float('inf')\n","    min_height = float('inf')\n","    \n","    for directory in os.listdir(people_path):\n","        #  Loop over every image in the directory\n","        for image in os.listdir(os.path.join(people_path, directory)):\n","            #  Load the image\n","            img = plt.imread(os.path.join(people_path, directory, image))\n","            img = rgb2gray(img)\n","            # resize image to width*height\n","            if (np.max(img) > 1):\n","                img = img / 255.0\n","            \n","            if(img.shape[0] < min_height):\n","                min_height = img.shape[0]\n","            if(img.shape[1] < min_width):\n","                min_width = img.shape[1]\n","                \n","            images.append(img)\n","            y[i] = [directory]\n","            i+=1\n","    \n","    images = np.array([cv2.resize(image, (100, 100))for image in images])\n","        \n","    return images, y"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(32, 100, 100)\n","32\n"]}],"source":["train_images, y = load_our_dataset()\n","print(train_images.shape)\n","print(len(y))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## PCA"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["def extract_pca_features(images, load=False, num_pca_components=0.95):\n","        image_vectors = []\n","        for image in images:\n","            image_vectors.append(image.flatten())\n","        image_vectors = np.array(image_vectors)\n","        \n","        if load:\n","            pca = pickle.load(open(parameters_path + \"\\our_faces_pca.pkl\", \"rb\"))\n","            pca_features = pca.transform(image_vectors)\n","            return pca_features\n","        else:\n","            print(\"Creating new PCA model...\")\n","            pca = PCA(n_components = num_pca_components, svd_solver = 'full')\n","            pca.fit(image_vectors)\n","\n","            pca_features = pca.transform(image_vectors)\n","\n","            pca_features = np.array(pca_features)\n","\n","            pickle.dump(pca, open(parameters_path + \"\\our_faces_pca.pkl\", \"wb\"))\n","            \n","            return pca_features"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Creating new PCA model...\n","PCA Features Train: (32, 15)\n"]}],"source":["pca_features_train = extract_pca_features(train_images,load=False, num_pca_components=0.95)\n","print(f'PCA Features Train: {pca_features_train.shape}')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
