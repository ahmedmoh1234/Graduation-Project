{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "from skimage.color import rgb2gray\n",
    "import pickle\n",
    "import os\n",
    "dirname = os.path.abspath('')\n",
    "datasets_path = os.path.join(dirname, 'Datasets')\n",
    "olivetti_path = os.path.join(datasets_path, 'Olivetti')\n",
    "parameters_path = os.path.join(dirname, 'PCA Parameters\\Olivetti')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------- LOAD OLIVIETTA DATASET ---------------------------- #\n",
    "\n",
    "lfw_people = fetch_olivetti_faces(data_home=olivetti_path, shuffle=True, random_state=47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: (400, 64, 64)\n",
      "Each image has size: 64 x 64\n",
      "----------------------------------------------------------------------\n",
      "N^2 = n_features = h x w = 4096\n",
      "----------------------------------------------------------------------\n",
      "y has shape: (400,)\n",
      "Number of people = 40\n"
     ]
    }
   ],
   "source": [
    "images = lfw_people.images\n",
    "print('Images shape:',images.shape)\n",
    "\n",
    "total_images, height, width = images.shape\n",
    "print(f'Each image has size: {height} x {width}')\n",
    "\n",
    "print(70* '-')\n",
    "\n",
    "n_features = height*width\n",
    "print(f'N^2 = n_features = h x w = {n_features}')\n",
    "\n",
    "print(70* '-')\n",
    "\n",
    "y = lfw_people.target\n",
    "print('y has shape:', y.shape)\n",
    "\n",
    "num_people = np.max(y) + 1\n",
    "print('Number of people =', num_people)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------- CREATE PEOPLE DICTIONARY -----------------------#\n",
    "\n",
    "# Key: person ID\n",
    "# Value: List of all person images indices\n",
    "person_image_dict = dict()\n",
    "\n",
    "for image_index in range(total_images):\n",
    "    if (y[image_index] not in person_image_dict.keys()):\n",
    "        person_image_dict[y[image_index]] = [image_index]\n",
    "    else:\n",
    "        person_image_dict[y[image_index]].append(image_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images shape: (320, 64, 64)\n",
      "Test images shape: (80, 64, 64)\n",
      "----------------------------------------------------------------------\n",
      "Number of train images: 320\n",
      "Number of test images: 80\n"
     ]
    }
   ],
   "source": [
    "train_images = []\n",
    "test_images = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "\n",
    "# guarantee that each person has at least 1 image in test set\n",
    "for image_index_lst in person_image_dict.values():\n",
    "    total_size = len(image_index_lst)\n",
    "    size_train = int(0.8 * total_size)\n",
    "    for index in range(len(image_index_lst)):\n",
    "        image = images[image_index_lst[index]]\n",
    "        label = y[image_index_lst[index]]\n",
    "        if (index < size_train):\n",
    "            train_images.append(image)\n",
    "            y_train.append(label)\n",
    "        else:\n",
    "            test_images.append(image)\n",
    "            y_test.append(label)\n",
    "    \n",
    "\n",
    "train_images = np.array(train_images)\n",
    "test_images = np.array(test_images)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print('Train images shape:', train_images.shape)\n",
    "print('Test images shape:', test_images.shape)\n",
    "\n",
    "m = train_images.shape[0]\n",
    "m_test = test_images.shape[0]\n",
    "print(70* '-')\n",
    "print('Number of train images:', m)\n",
    "print('Number of test images:', m_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: (400, 64, 64)\n",
      "Each image has size: 64 x 64\n",
      "----------------------------------------------------------------------\n",
      "M = Number of examples =  320\n",
      "M_test = Number of test examples =  80\n",
      "Train images shape: (320, 64, 64)\n",
      "Test images shape: (80, 64, 64)\n",
      "N^2 = n_features = h x w = 4096\n",
      "----------------------------------------------------------------------\n",
      "y has shape: (400,)\n",
      "y_train has shape: (320,)\n",
      "y_test has shape: (80,)\n",
      "Number of people = 40\n"
     ]
    }
   ],
   "source": [
    "images = lfw_people.images\n",
    "print('Images shape:',images.shape)\n",
    "\n",
    "total_images, height, width = images.shape\n",
    "print(f'Each image has size: {height} x {width}')\n",
    "\n",
    "print(70* '-')\n",
    "\n",
    "m = int(total_images * 0.8)\n",
    "print('M = Number of examples = ', m)\n",
    "\n",
    "m_test = total_images - m\n",
    "print('M_test = Number of test examples = ', m_test)\n",
    "\n",
    "train_images = images[:int(m)]\n",
    "print('Train images shape:', train_images.shape)\n",
    "\n",
    "test_images = images[int(m):]\n",
    "print('Test images shape:', test_images.shape)\n",
    "\n",
    "n_features = height*width\n",
    "print(f'N^2 = n_features = h x w = {n_features}')\n",
    "\n",
    "print(70* '-')\n",
    "\n",
    "y = lfw_people.target\n",
    "print('y has shape:', y.shape)\n",
    "\n",
    "y_train = y[:int(m)]\n",
    "print('y_train has shape:', y_train.shape)\n",
    "\n",
    "y_test = y[int(m):]\n",
    "print('y_test has shape:', y_test.shape)\n",
    "\n",
    "# target_names = lfw_people.target_names\n",
    "num_people = np.max(y) + 1\n",
    "print('Number of people =', num_people)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pca_features(images, load=False, num_pca_components=0.95):\n",
    "        image_vectors = []\n",
    "        for image in images:\n",
    "            image_vectors.append(image.flatten())\n",
    "        image_vectors = np.array(image_vectors)\n",
    "        \n",
    "        if load:\n",
    "            pca = pickle.load(open(parameters_path + \"\\olivetti_pca.pkl\", \"rb\"))\n",
    "            pca_features = pca.transform(image_vectors)\n",
    "            return pca_features\n",
    "        else:\n",
    "            print(\"Creating new PCA model...\")\n",
    "            pca = PCA(n_components = num_pca_components, svd_solver = 'full')\n",
    "            pca.fit(image_vectors)\n",
    "\n",
    "            pca_features = pca.transform(image_vectors)\n",
    "\n",
    "            pca_features = np.array(pca_features)\n",
    "\n",
    "            pickle.dump(pca, open(parameters_path + \"\\olivetti_pca.pkl\", \"wb\"))\n",
    "            \n",
    "            return pca_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new PCA model...\n",
      "PCA Features Train: (320, 112)\n",
      "PCA Features Test: (80, 112)\n"
     ]
    }
   ],
   "source": [
    "pca_features_train = extract_pca_features(train_images,load=False, num_pca_components=0.95)\n",
    "pca_features_test = extract_pca_features(test_images,load=True, num_pca_components=0.95)\n",
    "print(f'PCA Features Train: {pca_features_train.shape}')\n",
    "print(f'PCA Features Test: {pca_features_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_image(image, width, height):\n",
    "    # if image is RGB, convert to grayscale\n",
    "    if len(image.shape) > 2:\n",
    "        image = image[:,:,:3]\n",
    "        image = rgb2gray(image)\n",
    "    # resize image to width*height\n",
    "    image = cv2.resize(image, (width, height))\n",
    "    if (np.max(image) > 1):\n",
    "        image = image / 255.0\n",
    "    image = image.reshape((1, width*height))\n",
    "\n",
    "    return image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateDistance(x1, x2):\n",
    "    distance = np.linalg.norm(x1-x2)\n",
    "    return distance\n",
    "\n",
    "def KNN(test_point, training_features, labels, k):\n",
    "    distances = [calculateDistance(test_point, p) for p in training_features]\n",
    "    \n",
    "    #k_nearest: numpy array of size k holding indices of k nearest images\n",
    "    k_nearest = np.argpartition(distances, k)[:k]\n",
    "    # print(k_nearest)\n",
    "    \n",
    "    votes = np.zeros(num_people)\n",
    "\n",
    "    for i in k_nearest:\n",
    "        # print(i)\n",
    "        # print(labels[i])\n",
    "        # print('---')\n",
    "        votes[labels[i]] += 1\n",
    "\n",
    "    # print('---------------\\n',votes)\n",
    "    classification = np.argmax(votes)\n",
    "\n",
    "    return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 11, Actual: 11\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "test_point = pca_features_test[index]\n",
    "\n",
    "classification = KNN(test_point, pca_features_train, y_train, 5)\n",
    "\n",
    "print(f'Predicted: {classification}, Actual: {y_test[index]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.0%\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for index in range(m_test):\n",
    "    # Get image\n",
    "    test_point = pca_features_test[index]\n",
    "\n",
    "    classification = KNN(test_point, pca_features_train, y_train, 5)\n",
    "    \n",
    "    if(classification == y_test[index]):\n",
    "        count += 1\n",
    "    \n",
    "print(f'Accuracy: {count/m_test*100}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
