{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import skimage.io as io\n",
    "from skimage.color import rgb2gray\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = os.path.abspath('')\n",
    "datasets_path = os.path.join(dirname, 'Datasets')\n",
    "people_path = os.path.join(datasets_path, 'Our faces')\n",
    "test_images_path = os.path.join(dirname, 'Test Images')\n",
    "training_result_path = os.path.join(dirname, 'Training Result Data')\n",
    "omegas_path = os.path.join(training_result_path, 'omegas.npy')\n",
    "average_image_path = os.path.join(training_result_path, 'average_image.npy')\n",
    "eigenfaces_path = os.path.join(training_result_path, 'eigenfaces.npy')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_our_dataset():\n",
    "    #  Loop over every directory in people path\n",
    "    y = dict()\n",
    "    images = []\n",
    "    i=0\n",
    "    min_width = float('inf')\n",
    "    min_height = float('inf')\n",
    "    \n",
    "    for directory in os.listdir(people_path):\n",
    "        #  Loop over every image in the directory\n",
    "        for image in os.listdir(os.path.join(people_path, directory)):\n",
    "            #  Load the image\n",
    "            img = io.imread(os.path.join(people_path, directory, image))\n",
    "            img = rgb2gray(img)\n",
    "            # resize image to width*height\n",
    "            if (np.max(img) > 1):\n",
    "                img = img / 255.0\n",
    "            \n",
    "            if(img.shape[0] < min_height):\n",
    "                min_height = img.shape[0]\n",
    "            if(img.shape[1] < min_width):\n",
    "                min_width = img.shape[1]\n",
    "                \n",
    "            images.append(img)\n",
    "            y[i] = [directory]\n",
    "            i+=1\n",
    "    \n",
    "    images = np.array([cv2.resize(image, (min_height, min_width))for image in images])\n",
    "        \n",
    "    return images,y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Olivetti Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_olivetti_dataset():\n",
    "    dataset = fetch_olivetti_faces(data_home=\"D:\\Senior II\\Graduation Project\\Graduation-Project\\Eigenfaces\\Datasets\\Olivetti\"\n",
    "                                   , shuffle=True, random_state=42)\n",
    "    return dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images shape: (320, 64, 64)\n",
      "Test images shape: (80, 64, 64)\n",
      "----------------------------------------------------------------------\n",
      "Number of train images: 320\n",
      "Number of test images: 80\n"
     ]
    }
   ],
   "source": [
    "def train_test_split(lfw_people):\n",
    "    images = lfw_people.images\n",
    "    total_images, height, width = images.shape\n",
    "    n_features = height*width\n",
    "    y = lfw_people.target\n",
    "    num_people = np.max(y) + 1\n",
    "\n",
    "    # Key: person ID\n",
    "    # Value: List of all person images indices\n",
    "    person_image_dict = dict()\n",
    "\n",
    "    for image_index in range(total_images):\n",
    "        if (y[image_index] not in person_image_dict.keys()):\n",
    "            person_image_dict[y[image_index]] = [image_index]\n",
    "        else:\n",
    "            person_image_dict[y[image_index]].append(image_index)\n",
    "\n",
    "    train_images = []\n",
    "    test_images = []\n",
    "    y_train = []\n",
    "    y_test = []\n",
    "\n",
    "    # guarantee that each person has at least 1 image in test set\n",
    "    for image_index_lst in person_image_dict.values():\n",
    "        total_size = len(image_index_lst)\n",
    "        size_train = int(0.8 * total_size)\n",
    "        for index in range(len(image_index_lst)):\n",
    "            image = images[image_index_lst[index]]\n",
    "            label = y[image_index_lst[index]]\n",
    "            if (index < size_train):\n",
    "                train_images.append(image)\n",
    "                y_train.append(label)\n",
    "            else:\n",
    "                test_images.append(image)\n",
    "                y_test.append(label)\n",
    "    \n",
    "\n",
    "    train_images = np.array(train_images)\n",
    "    test_images = np.array(test_images)\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "\n",
    "    print('Train images shape:', train_images.shape)\n",
    "    print('Test images shape:', test_images.shape)\n",
    "\n",
    "    m = train_images.shape[0]\n",
    "    m_test = test_images.shape[0]\n",
    "    print(70* '-')\n",
    "    print('Number of train images:', m)\n",
    "    print('Number of test images:', m_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert images to gray scale and same shape of trained images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ---------------------------- CONVERT IMAGE TO GRAY SCALE AND SAME SHAPE OF TRAINED IMAGES ---------------------------- #\n",
    "\n",
    "def convert_image(image, width, height):\n",
    "    # plt.imshow(image, cmap='gray', label='Input image')\n",
    "    # plt.show()\n",
    "    # if image is RGB, convert to grayscale\n",
    "    if len(image.shape) > 2:\n",
    "        image = image[:,:,:3]\n",
    "        image = rgb2gray(image)\n",
    "    # resize image to width*height\n",
    "    image = cv2.resize(image, (width, height))\n",
    "    if (np.max(image) > 1):\n",
    "        image = image / 255.0\n",
    "    image = image.reshape((width*height, 1))\n",
    "    # Show image\n",
    "    # plt.imshow(image.reshape(height, width), cmap='gray', label='Input image')\n",
    "    # plt.show()\n",
    "\n",
    "    return image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flatten Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flattened_images(images, m, height, width, verbose=False):\n",
    "    # Flatten images array\n",
    "    # Each column is an image\n",
    "\n",
    "    # N^2 * M\n",
    "    flattened_images = images.reshape(m, -1).T\n",
    "\n",
    "    if(verbose):\n",
    "        print(\n",
    "            f'Shape of training images after flattening: {flattened_images.shape}')\n",
    "\n",
    "    return flattened_images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_image(flattened_images, height, width, verbose=False):\n",
    "    # In all corresponding pixels in all images, we calculate the average\n",
    "\n",
    "    # N^2 * 1\n",
    "    average_image = np.mean(flattened_images, axis=1)[:, np.newaxis]\n",
    "    if(verbose):\n",
    "        print(f'Average image has shape: {average_image.shape}')\n",
    "        plt.imshow(average_image.reshape(height, width),\n",
    "                   cmap='gray', title='Average Image')\n",
    "        plt.show()\n",
    "    return average_image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_difference_images(flattened_images, average_image, verbose=False):\n",
    "    # Subtract the average image from all images\n",
    "    # This is done to remove the average face from all images\n",
    "    # N^2 * M\n",
    "    difference_images = flattened_images - average_image\n",
    "    if(verbose):\n",
    "        print(\n",
    "            f'Shape after subtracting average face: {difference_images.shape}')\n",
    "    return difference_images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Difference Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_difference_image(difference_images, train_images, height, width, m):\n",
    "    # Show one difference image and compare to original\n",
    "    index = int(random.random() * m)\n",
    "\n",
    "    plt.imshow(difference_images[:, index].reshape(height, width), cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "    # Print original image\n",
    "    plt.imshow(train_images[index, :, :], cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_covariance_matrix(m, n_features, difference_images, verbose=False):\n",
    "    # C = A * A^T where A = difference_images\n",
    "    # N^2 * M\n",
    "    A = difference_images\n",
    "\n",
    "    if (m > n_features):\n",
    "        # N^2 * N^2\n",
    "        covariance_matrix = np.matmul(difference_images, difference_images.T)\n",
    "        if(verbose):\n",
    "            print('Shape of covariance matrix = N^2 * N^2 = ',\n",
    "                  covariance_matrix.shape)\n",
    "        return covariance_matrix\n",
    "\n",
    "    else:\n",
    "        # M * M\n",
    "        covariance_matrix = np.matmul(difference_images.T, difference_images)\n",
    "        if(verbose):\n",
    "            print('Shape of covariance matrix = M * M = ',\n",
    "                  covariance_matrix.shape)\n",
    "        return covariance_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigenvectors and Eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eigenvalues_eigenfaces(covariance_matrix, difference_images, verbose=False):\n",
    "    # M eigenvalues and M eigenvectors\n",
    "    # where M is the number of examples\n",
    "\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)\n",
    "\n",
    "    if(verbose):\n",
    "        print('Shape of eigenvalues:', eigenvalues.shape)\n",
    "        print('Shape of eigenvectors before matrix multiplication:',\n",
    "              eigenvectors.shape)\n",
    "\n",
    "    # Try to remove\n",
    "    eigenfaces = np.matmul(difference_images, eigenvectors)\n",
    "\n",
    "    if(verbose):\n",
    "        print('Shape of eigenfaces after matrix multiplication:', eigenfaces.shape)\n",
    "\n",
    "    return eigenvalues, eigenfaces"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Eigenfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_eigenfaces(eigenfaces, verbose=False):\n",
    "    eigenfaces = eigenfaces / np.linalg.norm(eigenfaces, axis=0)\n",
    "    if(verbose):\n",
    "        print('Shape of eigenfaces after normalization:', eigenfaces.shape)\n",
    "    return eigenfaces"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort Eigenfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_eigenvalues_eigenfaces(eigenvalues, eigenfaces):\n",
    "    # Get top K eigenfaces\n",
    "    indices_of_top_eigenvalues = np.argsort(-eigenvalues)\n",
    "    eigenvalues = eigenvalues[indices_of_top_eigenvalues]\n",
    "    eigenfaces = eigenfaces[:, indices_of_top_eigenvalues]\n",
    "    return eigenvalues, eigenfaces"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_K(eigenvalues, m, variance=0.8, verbose=False):\n",
    "    # Calculate the number of components to preserve specified variance\n",
    "    K = m\n",
    "    for ii, eigen_value_cumsum in enumerate(np.cumsum(eigenvalues) / np.sum(eigenvalues)):\n",
    "        if eigen_value_cumsum > variance:\n",
    "            K = ii\n",
    "            break\n",
    "\n",
    "    if(verbose):\n",
    "        print(\n",
    "            f'Number of components to preserve {variance*100}% of the variance = {K}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select K Top Eigenfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_K_top_eigenfaces(eigenvalues, eigenfaces, K, verbose=False):\n",
    "    # Select only K eigenfaces\n",
    "    eigenvalues = eigenvalues[:K].copy()\n",
    "    eigenfaces = eigenfaces[:, :K].copy()\n",
    "\n",
    "    if(verbose):\n",
    "        print('Shape of eigenvalues after selecting top K:', eigenvalues.shape)\n",
    "        # N^2 * K\n",
    "        print('Shape of eigenfaces after selecting top K:', eigenfaces.shape)\n",
    "    return eigenvalues, eigenfaces"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Eigenfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_eigenfaces(eigenfaces, height, width, K, num_show=16):\n",
    "    # Show eigenfaces\n",
    "    for i in range(min(K, num_show)):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(eigenfaces[:, i].reshape(height, width), cmap='gray')\n",
    "        plt.title(f'Eigenface {i+1}')\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show a random Eigenface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------ SHOW A RANDOM EIGENFACE ------------------------ #\n",
    "\n",
    "def show_random_eigenface(eigenfaces, height, width, m):\n",
    "    index = int(random.random() * m)\n",
    "    plt.imshow(eigenfaces[:, index].reshape(height, width), cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Omegas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------ CALCULATE OMEGAS ------------------------ #\n",
    "\n",
    "def get_omegas(difference_images, eigenfaces, verbose=False):\n",
    "    omegas = []\n",
    "    for image in difference_images.T:\n",
    "        omegas.append(np.dot(image, eigenfaces))\n",
    "    omegas = np.array(omegas)\n",
    "    if(verbose):\n",
    "        print('Shape of omegas:', omegas.shape)\n",
    "    return omegas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Parameters to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------ SAVE DATA TO DISK ------------------------ #\n",
    "\n",
    "def save_parameters_to_disk(omegas, eigenfaces, average_image):\n",
    "    np.save(omegas_path, omegas)\n",
    "    np.save(eigenfaces_path, eigenfaces)\n",
    "    np.save(average_image_path, average_image)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Info from Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info_from_our_dataset(images,y,verbose=False):\n",
    "    m = images.shape[0]\n",
    "    if(verbose):\n",
    "        print('Images shape:', images.shape)\n",
    "\n",
    "    total_images, height, width = images.shape\n",
    "    if(verbose):\n",
    "        print(f'Each image has size: {height} x {width}')\n",
    "        print(70 * '-')\n",
    "\n",
    "    n_features = height*width\n",
    "    if(verbose):\n",
    "        print(f'N^2 = n_features = h x w = {n_features}')\n",
    "        print(70 * '-')\n",
    "\n",
    "    if(verbose):\n",
    "        print('y has shape:', y.shape)\n",
    "\n",
    "    return images, m, height, width, total_images, n_features, y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_parameters():\n",
    "    omegas = np.load(omegas_path)\n",
    "    eigenfaces = np.load(eigenfaces_path)\n",
    "    average_image = np.load(average_image_path)\n",
    "    return omegas, eigenfaces, average_image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(omegas, test_image, average_image, eigenfaces, height, width, threshold=7):\n",
    "    # Predict the class of a test image\n",
    "    # Calculate omega for test image\n",
    "    omega = np.matmul((test_image - average_image).T, eigenfaces)\n",
    "\n",
    "    # Calculate distance between omega and all omegas\n",
    "    distances = np.linalg.norm(omegas - omega, axis=1)\n",
    "\n",
    "    # Get the index of the minimum distance\n",
    "    index = np.argmin(distances)\n",
    "\n",
    "    # Get min distance\n",
    "    min_distance = distances[index]\n",
    "    if(min_distance < threshold):\n",
    "        return index\n",
    "    else:\n",
    "        return -1  # Unknown"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Our Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_our():\n",
    "    images,y = load_our_dataset()\n",
    "    images, m, height, width, total_images, n_features, y = extract_info_from_our_dataset(images,y)\n",
    "    flattened_images = get_flattened_images(images, m, height, width)\n",
    "    average_image = get_average_image(flattened_images, height, width)\n",
    "    difference_images = get_difference_images(flattened_images, average_image)\n",
    "    covariance_matrix = get_covariance_matrix(m, n_features, difference_images)\n",
    "    eigenvalues, eigenfaces = eigenvalues_eigenfaces(covariance_matrix, difference_images)\n",
    "    eigenfaces = normalize_eigenfaces(eigenfaces)\n",
    "    eigenvalues, eigenfaces = sort_eigenvalues_eigenfaces(eigenvalues, eigenfaces)\n",
    "    K = calculate_K(eigenvalues, m)\n",
    "    eigenvalues, eigenfaces = select_K_top_eigenfaces(eigenvalues, eigenfaces, K)\n",
    "    omegas = get_omegas(difference_images, eigenfaces)\n",
    "    save_data_to_disk(omegas, eigenfaces, average_image)\n",
    "train_our()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------- TESTING ACCURACY ---------------------------- #\n",
    "count = 0\n",
    "trials = 1000\n",
    "for trial in range(trials):\n",
    "    # Get test image index randomly\n",
    "    index = int(random.random() * m_test)\n",
    "    \n",
    "    # Get image\n",
    "    test_image = flattened_test_images[:,index, np.newaxis]\n",
    "\n",
    "    min_distance = float('inf')\n",
    "    nearest_person = -1\n",
    "\n",
    "\n",
    "    omega_image = np.matmul((test_image - average_image).T, eigenvectors)\n",
    "\n",
    "    for i in range(m):\n",
    "        omega = omegas[i]\n",
    "        distance = np.linalg.norm(omega_image - omega)\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            nearest_person = i\n",
    "\n",
    "    \n",
    "    threshold = float('inf')\n",
    "    if (min_distance < threshold):\n",
    "        if(y_train[nearest_person] == y_test[index]):\n",
    "            count += 1\n",
    "print(f'Accuracy: {count/trials*100}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognizer_main(input_image):\n",
    "    # dataset = load_olivetti_dataset()\n",
    "    # images, _, height, width, _, _, _, _ = extract_info_from_olivetti_dataset(dataset)\n",
    "    images, y = load_our_dataset()\n",
    "    images, _, height, width, _, _, _ = extract_info_from_our_dataset(images,y)\n",
    "    \n",
    "    omegas, eigenfaces, average_image = load_parameters()\n",
    "    input_image = convert_image(input_image, width, height)\n",
    "    plt.imshow(input_image.reshape(height,width), cmap='gray', label='Input image')\n",
    "    plt.show()\n",
    "\n",
    "    predicted_index = predict(omegas, input_image, average_image, eigenfaces, height, width, 120)\n",
    "    if (predicted_index == -1):\n",
    "        print('Unknown face')\n",
    "    else:\n",
    "        print('Known face')\n",
    "        # show predicted image\n",
    "        print(\"Image Index: \", predicted_index)\n",
    "        print(\"Target Index: \", y[predicted_index])\n",
    "        plt.imshow(images[predicted_index],cmap='gray', label='Predicted image')\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
