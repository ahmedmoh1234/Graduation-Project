{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a convolutional neural network (CNN)\n",
    "model = tf.keras.quential([\n",
    "    Cotf.keras.layers.nv2D(32, (3, 3), activation='relu', input_shape=(200, 200, 3)),\n",
    "    Matf.keras.layers.xPooling2D(2, 2),\n",
    "    Cotf.keras.layers.nv2D(64, (3, 3), activation='relu'),\n",
    "    Matf.keras.layers.xPooling2D(2, 2),\n",
    "    Cotf.keras.layers.nv2D(128, (3, 3), activation='relu'),\n",
    "    Matf.keras.layers.xPooling2D(2, 2),\n",
    "    Fltf.keras.layers.atten(),\n",
    "    Detf.keras.layers.nse(128, activation='relu'),\n",
    "    Detf.keras.layers.nse(len(clothing_names), activation='softmax')\n",
    "])tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------IMPORTS----------------------------\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'D:\\Senior II\\Graduation Project\\Datasets\\Clothes'\n",
    "df = pd.read_csv(path + '/images.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove all entries with label = Not sure\n",
    "df = df[df['label'] != 'Not sure']\n",
    "#Remove colums: sender_id and kids\n",
    "df = df.drop(['sender_id', 'kids'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the unique labels\n",
    "class_names = df['label'].unique()\n",
    "print(f'There are {class_names.shape[0]} unique classes')\n",
    "class_ids = dict()\n",
    "for i in range(len(class_names)):\n",
    "    class_ids[class_names[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width = image_height = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upload photos to a numpy array\n",
    "images_train = []\n",
    "images_labels_train = []\n",
    "images_test = []\n",
    "images_labels_test = []\n",
    "# for i in range(len(df['image'])):\n",
    "for i in range(1000):\n",
    "    #Check if df['image'][i] is in\n",
    "    if (i in df['image'].keys()):\n",
    "        img = cv2.imread(path + '/' + df['image'][i] + '.jpg')\n",
    "        #Check if image is not None\n",
    "        if (img is not None):\n",
    "            images_train.append(cv2.resize(img, (image_width, image_height)))\n",
    "            images_labels_train.append(class_ids[df['label'][i]])\n",
    "\n",
    "for j in range(300):\n",
    "    #Check if df['image'][i] is in\n",
    "    if ((i + j) in df['image'].keys()):\n",
    "        img = cv2.imread(path + '/' + df['image'][i + j] + '.jpg')\n",
    "        #Check if image is not None\n",
    "        if (img is not None):\n",
    "            images_test.append(cv2.resize(img, (image_width, image_height)))\n",
    "            images_labels_test.append(class_ids[df['label'][i + j]])\n",
    "\n",
    "            \n",
    "x_train = np.array(images_train)\n",
    "y_train = np.array(images_labels_train)\n",
    "\n",
    "x_test = np.array(images_test)\n",
    "y_test = np.array(images_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show an image from x_train\n",
    "plt.imshow(x_train[401])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of training examples\n",
    "m = x_train.shape[0]\n",
    "m_test = x_test.shape[0]\n",
    "\n",
    "#Reshape the training and test examples\n",
    "# x_train = x_train.reshape(m, -1)\n",
    "# x_test = x_test.reshape(m_test, -1)\n",
    "\n",
    "print(f'x_train.shape = {x_train.shape}')\n",
    "print(f'y_train.shape = {y_train.shape}')\n",
    "print(f'x_test.shape = {x_test.shape}')\n",
    "print(f'y_test.shape = {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a convolutional neural network (CNN)\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape = (image_width, image_height,3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(len(class_names), activation='linear')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),  #<-- Note\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the training data\n",
    "# history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))\n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot loss vs epochs\n",
    "plt.plot(history.history['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, train_accuracy = model.evaluate(x_train, y_train)\n",
    "_, test_accuracy = model.evaluate(x_test, y_test)\n",
    "print(\"Train Accuracy = %.2f\" % (train_accuracy*100),'% with', m, 'training examples')\n",
    "print(\"Test Accuracy = %.2f\" % (test_accuracy*100),'% with', m_test, 'test examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = model.predict(x_train)\n",
    "test_predictions = model.predict(x_test)\n",
    "train_count_correct = 0\n",
    "test_count_correct = 0\n",
    "for i in range(m):\n",
    "    predicted = np.argmax(train_predictions[i])\n",
    "    if (predicted == y_train[i]):\n",
    "        train_count_correct += 1\n",
    "train_accuracy = train_count_correct / m\n",
    "\n",
    "for i in range(m_test):\n",
    "    predicted = np.argmax(test_predictions[i])\n",
    "    if (predicted == y_test[i]):\n",
    "        test_count_correct += 1\n",
    "test_accuracy = test_count_correct / m_test\n",
    "\n",
    "print(\"Train Accuracy = %.2f\" % (train_accuracy*100),'% with', m, 'training examples')\n",
    "print(\"Test Accuracy = %.2f\" % (test_accuracy*100),'% with', m_test, 'test examples')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(x_train[np.newaxis,0])\n",
    "prediction\n",
    "class_names[np.argmax(prediction)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "pickle.dump(model, open('clothing_detector.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a summary of your model's architecture\n",
    "tf.keras.utils.plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "20aebf7f160902ad9dd8cbfe460d54a7c92755b430d8a2756048c9f24f1ce0aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
