{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a convolutional neural network (CNN)\n",
    "model = tf.keras.quential([\n",
    "    Cotf.keras.layers.nv2D(32, (3, 3), activation='relu', input_shape=(200, 200, 3)),\n",
    "    Matf.keras.layers.xPooling2D(2, 2),\n",
    "    Cotf.keras.layers.nv2D(64, (3, 3), activation='relu'),\n",
    "    Matf.keras.layers.xPooling2D(2, 2),\n",
    "    Cotf.keras.layers.nv2D(128, (3, 3), activation='relu'),\n",
    "    Matf.keras.layers.xPooling2D(2, 2),\n",
    "    Fltf.keras.layers.atten(),\n",
    "    Detf.keras.layers.nse(128, activation='relu'),\n",
    "    Detf.keras.layers.nse(len(clothing_names), activation='softmax')\n",
    "])tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------IMPORTS----------------------------\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.activations import relu\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'D:\\Senior II\\Graduation Project\\Datasets\\Clothes'\n",
    "df = pd.read_csv(path + '/images.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove all entries with label = Not sure\n",
    "df = df[df['label'] != 'Not sure']\n",
    "#Remove colums: sender_id and kids\n",
    "df = df.drop(['sender_id', 'kids'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the unique labels\n",
    "class_names = df['label'].unique()\n",
    "print(f'There are {class_names.shape[0]} unique classes')\n",
    "class_ids = dict()\n",
    "for i in range(len(class_names)):\n",
    "    class_ids[class_names[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width = 128\n",
    "image_height = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upload photos to a numpy array\n",
    "images_train = []\n",
    "images_labels_train = []\n",
    "images_test = []\n",
    "images_labels_test = []\n",
    "# for i in range(len(df['image'])):\n",
    "for i in range(1000):\n",
    "    #Check if df['image'][i] is in\n",
    "    if (i in df['image'].keys()):\n",
    "        img = cv2.imread(path + '/' + df['image'][i] + '.jpg')\n",
    "        #Check if image is not None\n",
    "        if (img is not None):\n",
    "            images_train.append(cv2.resize(img, (image_width, image_height)))\n",
    "            images_labels_train.append(class_ids[df['label'][i]])\n",
    "\n",
    "for j in range(300):\n",
    "    #Check if df['image'][i] is in\n",
    "    if ((i + j) in df['image'].keys()):\n",
    "        img = cv2.imread(path + '/' + df['image'][i + j] + '.jpg')\n",
    "        #Check if image is not None\n",
    "        if (img is not None):\n",
    "            images_test.append(cv2.resize(img, (image_width, image_height)))\n",
    "            images_labels_test.append(class_ids[df['label'][i + j]])\n",
    "\n",
    "            \n",
    "x_train = np.array(images_train)\n",
    "y_train = np.array(images_labels_train)\n",
    "\n",
    "x_test = np.array(images_test)\n",
    "y_test = np.array(images_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show an image from x_train\n",
    "plt.imshow(x_train[401])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of training examples\n",
    "m = x_train.shape[0]\n",
    "m_test = x_test.shape[0]\n",
    "\n",
    "#Reshape the training and test examples\n",
    "# x_train = x_train.reshape(m, -1)\n",
    "# x_test = x_test.reshape(m_test, -1)\n",
    "\n",
    "print(f'x_train.shape = {x_train.shape}')\n",
    "print(f'y_train.shape = {y_train.shape}')\n",
    "print(f'x_test.shape = {x_test.shape}')\n",
    "print(f'y_test.shape = {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a convolutional neural network (CNN)\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape = (image_width, image_height,3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    Dense(len(class_names), activation='softmax')\n",
    "])\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a summary of your model's architecture\n",
    "plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "31/31 [==============================] - 9s 267ms/step - loss: 28.8212 - accuracy: 0.1582\n",
      "Epoch 2/10\n",
      "31/31 [==============================] - 8s 254ms/step - loss: 4.6015 - accuracy: 0.2820\n",
      "Epoch 3/10\n",
      "31/31 [==============================] - 8s 256ms/step - loss: 4.1024 - accuracy: 0.3850\n",
      "Epoch 4/10\n",
      "31/31 [==============================] - 8s 254ms/step - loss: 3.5147 - accuracy: 0.5193\n",
      "Epoch 5/10\n",
      "31/31 [==============================] - 8s 254ms/step - loss: 2.8947 - accuracy: 0.6722\n",
      "Epoch 6/10\n",
      "31/31 [==============================] - 8s 255ms/step - loss: 2.4343 - accuracy: 0.8044\n",
      "Epoch 7/10\n",
      "31/31 [==============================] - 8s 259ms/step - loss: 2.1374 - accuracy: 0.8668\n",
      "Epoch 8/10\n",
      "31/31 [==============================] - 8s 258ms/step - loss: 2.2410 - accuracy: 0.8262\n",
      "Epoch 9/10\n",
      "31/31 [==============================] - 8s 258ms/step - loss: 1.9745 - accuracy: 0.9074\n",
      "Epoch 10/10\n",
      "31/31 [==============================] - 8s 259ms/step - loss: 1.7772 - accuracy: 0.9501\n"
     ]
    }
   ],
   "source": [
    "# Train the model on the training data\n",
    "# history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))\n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot loss vs epochs\n",
    "plt.plot(history.history['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 2s 60ms/step - loss: 1.7674 - accuracy: 0.9615\n",
      "10/10 [==============================] - 1s 59ms/step - loss: 5.1073 - accuracy: 0.3966\n",
      "Train Accuracy = 96.15 % with 961 training examples\n",
      "Test Accuracy = 39.66 % with 295 test examples\n"
     ]
    }
   ],
   "source": [
    "_, train_accuracy = model.evaluate(x_train, y_train)\n",
    "_, test_accuracy = model.evaluate(x_test, y_test)\n",
    "print(\"Train Accuracy = %.2f\" % (train_accuracy*100),'% with', m, 'training examples')\n",
    "print(\"Test Accuracy = %.2f\" % (test_accuracy*100),'% with', m_test, 'test examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\\conv2d\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv2d_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv2d_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\flatten\n",
      "......vars\n",
      "...layers\\max_pooling2d\n",
      "......vars\n",
      "...layers\\max_pooling2d_1\n",
      "......vars\n",
      "...layers\\max_pooling2d_2\n",
      "......vars\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean_metric_wrapper\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........15\n",
      ".........16\n",
      ".........17\n",
      ".........18\n",
      ".........19\n",
      ".........2\n",
      ".........20\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-02-04 01:51:32         3931\n",
      "metadata.json                                  2023-02-04 01:51:32           64\n",
      "variables.h5                                   2023-02-04 01:51:32     39722544\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "pickle.dump(model, open('clothing_detector.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "20aebf7f160902ad9dd8cbfe460d54a7c92755b430d8a2756048c9f24f1ce0aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
