{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ''\n",
    "df = pd.read_csv(path + '/images.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove all entries with label = Not sure\n",
    "df = df[df['label'] != 'Not sure']\n",
    "#Remove colums: sender_id and kids\n",
    "df = df.drop(['sender_id', 'kids'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a convolutional neural network (CNN)\n",
    "model = tf.keras.quential([\n",
    "    Cotf.keras.layers.nv2D(32, (3, 3), activation='relu', input_shape=(200, 200, 3)),\n",
    "    Matf.keras.layers.xPooling2D(2, 2),\n",
    "    Cotf.keras.layers.nv2D(64, (3, 3), activation='relu'),\n",
    "    Matf.keras.layers.xPooling2D(2, 2),\n",
    "    Cotf.keras.layers.nv2D(128, (3, 3), activation='relu'),\n",
    "    Matf.keras.layers.xPooling2D(2, 2),\n",
    "    Fltf.keras.layers.atten(),\n",
    "    Detf.keras.layers.nse(128, activation='relu'),\n",
    "    Detf.keras.layers.nse(len(clothing_names), activation='softmax')\n",
    "])tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------IMPORTS----------------------------\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.activations import relu\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training dataset\n",
    "textures = ['cotton', 'linen', 'wool', 'silk']\n",
    "types = ['shirt', 't-shirt', 'jeans', 'dress']\n",
    "\n",
    "# Dictionary to store name of texture and type\n",
    "clothing_names = {}\n",
    "for i, t in enumerate(textures):\n",
    "    for j, ty in enumerate(types):\n",
    "        clothing_names[i*len(types) + j] = f'{t} {ty}'\n",
    "\n",
    "# List to store image data and labels\n",
    "data = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'dataset/cotton/shirt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m \u001b[39mtype\u001b[39m \u001b[39min\u001b[39;00m types:\n\u001b[0;32m      4\u001b[0m     path \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdataset/\u001b[39m\u001b[39m{\u001b[39;00mtexture\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m----> 5\u001b[0m     \u001b[39mfor\u001b[39;00m img_path \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39;49mlistdir(path):\n\u001b[0;32m      6\u001b[0m         img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mimg_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m         data\u001b[39m.\u001b[39mappend(img)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'dataset/cotton/shirt'"
     ]
    }
   ],
   "source": [
    "# Load images from the training dataset\n",
    "for texture in textures:\n",
    "    for type in types:\n",
    "        path = f'dataset/{texture}/{type}'\n",
    "        for img_path in os.listdir(path):\n",
    "            img = cv2.imread(f'{path}/{img_path}')\n",
    "            data.append(img)\n",
    "            labels.append(clothing_names.index(f'{texture} {type}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data and labels to numpy arrays\n",
    "data = np.array(data, dtype='float32')\n",
    "labels = np.array(labels, dtype='int32')\n",
    "\n",
    "# Normalize the data\n",
    "data /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Split the data into training and testing sets\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m split \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39m0.8\u001b[39m \u001b[39m*\u001b[39m data\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39m])\n\u001b[0;32m      3\u001b[0m x_train \u001b[39m=\u001b[39m data[:split]\n\u001b[0;32m      4\u001b[0m y_train \u001b[39m=\u001b[39m labels[:split]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "split = int(0.8 * data.shape[0])\n",
    "x_train = data[:split]\n",
    "y_train = labels[:split]\n",
    "x_test = data[split:]\n",
    "y_test = labels[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a convolutional neural network (CNN)\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(200, 200, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(len(clothing_names), activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unexpected result of `train_function` (Empty logs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Train the model on the training data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(x_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(x_test, y_test))\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1576\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1574\u001b[0m logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[0;32m   1575\u001b[0m \u001b[39mif\u001b[39;00m logs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1576\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1577\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUnexpected result of `train_function` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1578\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m(Empty logs). Please use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1579\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`Model.compile(..., run_eagerly=True)`, or \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1580\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`tf.config.run_functions_eagerly(True)` for more \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1581\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minformation of where went wrong, or file a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1582\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39missue/bug to `tf.keras`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1583\u001b[0m     )\n\u001b[0;32m   1584\u001b[0m epoch_logs \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mcopy(logs)\n\u001b[0;32m   1586\u001b[0m \u001b[39m# Run validation.\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Unexpected result of `train_function` (Empty logs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`."
     ]
    }
   ],
   "source": [
    "# Train the model on the training data\n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://34f50d19-5b0b-4c63-8af0-02ced8f5eaae/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://34f50d19-5b0b-4c63-8af0-02ced8f5eaae/assets\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "pickle.dump(model, open('clothing_detector.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16 (main, Jan 11 2023, 16:16:36) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
