{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from dataloader.dataloader import DataLoader\n",
    "from model_selection.model_selection import ModelSelection\n",
    "from performance_analysis.performance_analysis import PerformanceAnalysis\n",
    "from imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "\"Wool\",\n",
    "\"Denim\",\n",
    "\"Leather\",\n",
    "\"Cotton\",\n",
    "\"Silk\"\n",
    "    ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total count: 16\n",
      "current count: 6\n",
      "total count: 17\n",
      "current count: 7\n",
      "total count: 18\n",
      "current count: 8\n",
      "total count: 19\n",
      "current count: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Work\\CCE\\Year 4 - Senior 2\\Semester 1\\Senior-2-Semester-1\\GP\\Graduation-Project\\Clothes Description Module\\YOLO Clothes Detection and classification\\Texture Detection\\dataloader\\dataloader.py:76: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  pca_features = self.feature_selector.extract_pca_features(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m dataloader \u001b[39m=\u001b[39m DataLoader(Path(\u001b[39m'\u001b[39m\u001b[39m./data\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m----> 3\u001b[0m x_train, y_train, x_test, y_test, x_val, y_val \u001b[39m=\u001b[39m dataloader\u001b[39m.\u001b[39;49mload_data()\n",
      "File \u001b[1;32md:\\Work\\CCE\\Year 4 - Senior 2\\Semester 1\\Senior-2-Semester-1\\GP\\Graduation-Project\\Clothes Description Module\\YOLO Clothes Detection and classification\\Texture Detection\\dataloader\\dataloader.py:85\u001b[0m, in \u001b[0;36mDataLoader.load_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfirst \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 85\u001b[0m     pca_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_selector\u001b[39m.\u001b[39;49mextract_pca_features(\n\u001b[0;32m     86\u001b[0m         daisy_features, load\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, num_pca_components\u001b[39m=\u001b[39;49m \u001b[39m0.8\u001b[39;49m\n\u001b[0;32m     87\u001b[0m     )\n\u001b[0;32m     89\u001b[0m images_features \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((glcm_features, pca_features), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     91\u001b[0m x_train_temp, x_val_temp, y_train_temp, y_val_temp \u001b[39m=\u001b[39m train_test_split(\n\u001b[0;32m     92\u001b[0m     images_features, labels, test_size\u001b[39m=\u001b[39m\u001b[39m0.15\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m\n\u001b[0;32m     93\u001b[0m )\n",
      "File \u001b[1;32md:\\Work\\CCE\\Year 4 - Senior 2\\Semester 1\\Senior-2-Semester-1\\GP\\Graduation-Project\\Clothes Description Module\\YOLO Clothes Detection and classification\\Texture Detection\\feature_selection\\feature_selection.py:27\u001b[0m, in \u001b[0;36mFeatureSelector.extract_pca_features\u001b[1;34m(self, images, load, num_pca_components)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[39mif\u001b[39;00m load:\n\u001b[0;32m     26\u001b[0m     pca \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(\u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mpca.pkl\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m---> 27\u001b[0m     pca_features \u001b[39m=\u001b[39m pca\u001b[39m.\u001b[39;49mtransform(image_vectors)\n\u001b[0;32m     28\u001b[0m     \u001b[39mreturn\u001b[39;00m pca_features\n\u001b[0;32m     29\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Moust\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Moust\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\decomposition\\_base.py:120\u001b[0m, in \u001b[0;36m_BasePCA.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Apply dimensionality reduction to X.\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \n\u001b[0;32m    103\u001b[0m \u001b[39mX is projected on the first principal components previously extracted\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[39m    is the number of samples and `n_components` is the number of the components.\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    118\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 120\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, dtype\u001b[39m=\u001b[39;49m[np\u001b[39m.\u001b[39;49mfloat64, np\u001b[39m.\u001b[39;49mfloat32], reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    121\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmean_ \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m     X \u001b[39m=\u001b[39m X \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmean_\n",
      "File \u001b[1;32mc:\\Users\\Moust\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    563\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    564\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 565\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[0;32m    566\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    567\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32mc:\\Users\\Moust\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    877\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    878\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 879\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[0;32m    880\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    881\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    882\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    883\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Moust\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    182\u001b[0m     xp, _ \u001b[39m=\u001b[39m get_namespace(array)\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m xp\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnumpy.array_api\u001b[39m\u001b[39m\"\u001b[39m}:\n\u001b[0;32m    184\u001b[0m     \u001b[39m# Use NumPy API to support order\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39masarray(array, order\u001b[39m=\u001b[39morder, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m    186\u001b[0m     \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m    187\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(Path('./data'))\n",
    "\n",
    "x_train, y_train, x_test, y_test, x_val, y_val = dataloader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"x_val shape: {x_val.shape}\")\n",
    "print(f\"y_val shape: {y_val.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show random image from train and corresponding class\n",
    "index = random.randint(0, len(x_train) - 1)\n",
    "print(index)\n",
    "\n",
    "print(x_train[index])\n",
    "# plt.imshow(x_train[index])\n",
    "# plt.show()\n",
    "print(f\"class= {classes[y_train[index]]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Extraction And Selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLCM Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_extractor = FeatureExtractor()\n",
    "\n",
    "# glcm_features_train = feature_extractor.extract_glcm_features(x_train)\n",
    "# glcm_features_val = feature_extractor.extract_glcm_features(x_val)\n",
    "\n",
    "# print(f\"extracted_features shape: {glcm_features_train.shape}\")\n",
    "# print(f\"extracted_features_val shape: {glcm_features_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for i in range(5):\n",
    "#     print(f\"Current fabric: {classes[y_train[i]]}\")\n",
    "#     print(f\"extracted glcm Features:{glcm_features_train[i]}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selection = ModelSelection(x_train, y_train, x_val, y_val)\n",
    "\n",
    "svm, pred_train, pred_val = model_selection.SVM()\n",
    "performance_analysis = PerformanceAnalysis('SVM Train', pred_train, y_train)\n",
    "performance_analysis.calculate_performance_metrics()\n",
    "performance_analysis = PerformanceAnalysis('SVM VALIDATION', pred_val, y_val, True)\n",
    "performance_analysis.calculate_performance_metrics()\n",
    "\n",
    "\n",
    "knn, pred_train, pred_val = model_selection.KNN()\n",
    "performance_analysis = PerformanceAnalysis('KNN Train', pred_train, y_train)\n",
    "performance_analysis.calculate_performance_metrics()\n",
    "performance_analysis = PerformanceAnalysis('KNN VALIDATION', pred_val, y_val, True)\n",
    "performance_analysis.calculate_performance_metrics()\n",
    "\n",
    "ensemble, pred_train, pred_val = model_selection.Ensemble()\n",
    "performance_analysis = PerformanceAnalysis('Ensemble Train', pred_train, y_train)\n",
    "performance_analysis.calculate_performance_metrics()\n",
    "performance_analysis = PerformanceAnalysis('Ensemble VALIDATION', pred_val, y_val, True)\n",
    "performance_analysis.calculate_performance_metrics()\n",
    "\n",
    "\n",
    "adaboost, pred_train, pred_val = model_selection.AdaBoost()\n",
    "performance_analysis = PerformanceAnalysis('AdaBoost Train', pred_train, y_train)\n",
    "performance_analysis.calculate_performance_metrics()\n",
    "performance_analysis = PerformanceAnalysis('AdaBoost VALIDATION', pred_val, y_val, True)\n",
    "performance_analysis.calculate_performance_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selection = ModelSelection(x_train, y_train, x_val, y_val)\n",
    "\n",
    "ann, pred_train, pred_val = model_selection.ANN(input_dim=x_train.shape[1], \n",
    "                                                output_dim=15)\n",
    "performance_analysis = PerformanceAnalysis('ANN Train', pred_train, y_train)\n",
    "performance_analysis.calculate_performance_metrics()\n",
    "performance_analysis = PerformanceAnalysis('ANN Val', pred_val, y_val, True)\n",
    "performance_analysis.calculate_performance_metrics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
